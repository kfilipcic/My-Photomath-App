{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/validation dataset preprocessing\n",
    "\n",
    "For training the CNN model, three datasets were combined:\n",
    "\n",
    "1. MNIST dataset (contains 20x20 images which are numbers from 0 to 9)\n",
    "2. Kaggle Handwritten math symbol and digit dataset: Used for all the symbols, numbers were also merged with MNIST dataset numbers (https://www.kaggle.com/clarencezhao/handwritten-math-symbol-dataset)\n",
    "3. Because there was only a small number of forward slashes (division symbols) in the second dataset, the \"backslashes\" from this dataset were taken, mirrored and processed to act like forward slashed - but still there are only ~430 forward slashes in the entire dataset! (https://www.kaggle.com/guru001/hasyv2)\n",
    "\n",
    "The code below was used for processing and merging input datasets into one. It results in a MNIST dataset format (20x20 size, white characters and black background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "working_dir = '/home/cec/Downloads/handwritten_math_symbols_kaggle/extracted_images'\n",
    "working_dir2 = '/home/cec/Documents/photomath'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path in os.listdir(working_dir2 + '/backslash'):\n",
    "    if '.png' not in image_path:\n",
    "        continue\n",
    "    img = cv2.imread(working_dir2 + '/backslash/' + image_path, 0)\n",
    "    # Flip backslash horizontally so it becomes a forward slash\n",
    "    img = cv2.flip(img, 1)\n",
    "    cv2.imwrite(working_dir2 + '/backslash/' + image_path, img)\n",
    "    #cv2.imshow('img', img)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:35: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:35: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-24-5142201a781d>:35: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): # color image but only one color provided\n"
     ]
    }
   ],
   "source": [
    "# Image preprocessing\n",
    "\n",
    "def resizeAndPad(img, size, padColor=0):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "\n",
    "    # interpolation method\n",
    "    if h > sh or w > sw: # shrinking image\n",
    "        interp = cv2.INTER_AREA\n",
    "    else: # stretching image\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    # aspect ratio of image\n",
    "    aspect = w/h  # if on Python 2, you might need to cast as a float: float(w)/h\n",
    "\n",
    "    # compute scaling and pad sizing\n",
    "    if aspect > 1: # horizontal image\n",
    "        new_w = sw\n",
    "        new_h = np.round(new_w/aspect).astype(int)\n",
    "        pad_vert = (sh-new_h)/2\n",
    "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "        pad_left, pad_right = 0, 0\n",
    "    elif aspect < 1: # vertical image\n",
    "        new_h = sh\n",
    "        new_w = np.round(new_h*aspect).astype(int)\n",
    "        pad_horz = (sw-new_w)/2\n",
    "        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
    "        pad_top, pad_bot = 0, 0\n",
    "    else: # square image\n",
    "        new_h, new_w = sh, sw\n",
    "        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "\n",
    "    # set pad color\n",
    "    if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): # color image but only one color provided\n",
    "        padColor = [padColor]*3\n",
    "\n",
    "    # scale and pad\n",
    "    scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)\n",
    "    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)\n",
    "\n",
    "    return scaled_img\n",
    "\n",
    "# Symbols from Kaggle Handwritten Mathematical Symbols Dataset (45x45) need to \n",
    "# match MNIST dataset digits (28x28)\n",
    "working_dir = working_dir2\n",
    "for filename in os.listdir(working_dir):\n",
    "    #if filename in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']:\n",
    "    if filename in ['backslash']:\n",
    "        for image_path in os.listdir(working_dir + '/' + filename):\n",
    "            if '.jpg' not in image_path and '.png' not in image_path:\n",
    "                continue\n",
    "            # Read image in grayscale\n",
    "            image = cv2.imread(working_dir + '/' + filename + '/' + image_path, 0)\n",
    "\n",
    "            # Invert black and white colors\n",
    "            image = cv2.bitwise_not(image)\n",
    "            \n",
    "            # Make image binary\n",
    "            image = cv2.threshold(image, 150, 255, cv2.THRESH_BINARY)[1]\n",
    "            \n",
    "            # Kernel for erosion and dilation\n",
    "            kernel = np.ones((5,5),np.uint8)\n",
    "            \n",
    "            # Dilating images for symbols to be thicker\n",
    "            # because it seems that MNIST dataset has thicker\n",
    "            # numbers than are symbols in the Kaggle dataset\n",
    "            # So we are going to try to make these symbols\n",
    "            # be thicker to match the MNIST dataset \"thickness\"\n",
    "            image = cv2.dilate(image,kernel,iterations = 1)\n",
    "            \n",
    "            # Resize to 20x20 preserving aspect ratio\n",
    "            image = resizeAndPad(image, (20, 20))\n",
    "            \n",
    "            # Pad the image so it ends up being 28x28\n",
    "            # (just like MNIST dataset images are)\n",
    "            image = cv2.copyMakeBorder(image, 4, 4, 4, 4, borderType=cv2.BORDER_CONSTANT)\n",
    "            \n",
    "            #cv2.imshow('img', image)\n",
    "            #cv2.waitKey(0)\n",
    "            #cv2.destroyAllWindows()   \n",
    "            \n",
    "            # Save the modified image\n",
    "            image_path_splitted = image_path.split('.')\n",
    "            if not os.path.isdir('/home/cec/Documents/photomath/' + filename + '_converted'):\n",
    "                os.mkdir('/home/cec/Documents/photomath/' + filename + '_converted')\n",
    "            cv2.imwrite('/home/cec/Documents/photomath' + '/' + filename + '_converted/' + image_path_splitted[0] + '_mnist' + '.' + image_path_splitted[1], image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aibook",
   "language": "python",
   "name": "aibook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
